{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import datetime\n",
    "import talos\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from talos.utils import live, early_stopper\n",
    "from talos.utils.best_model import activate_model\n",
    "from keras import backend as K\n",
    "from keras import optimizers, losses\n",
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import (Activation, Conv2D, Dense, Dropout, Flatten, MaxPooling2D)\n",
    "from keras.models import Sequential\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet import ResNet50, ResNet101, ResNet152\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2, ResNet101V2, ResNet152V2\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import multilabel_confusion_matrix, classification_report, roc_curve, f1_score, accuracy_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, run):\n",
    "    plot_path = Path(\"plots/\" + str(run) + \"_\"+ datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \".pdf\")\n",
    "    plt.plot(history.history['loss'], label='Train MAE')\n",
    "    plt.plot(history.history['val_loss'], label='Val MAE')\n",
    "    plt.plot(history.history['f1score'], label='Train f1')\n",
    "    plt.plot(history.history['val_f1score'], label='Val f1')\n",
    "    plt.plot(history.history['acc'], label='Train Acc')\n",
    "    plt.plot(history.history['val_acc'], label='Val Acc')\n",
    "    plt.title('MAE F1 and Accuracy for CNN')\n",
    "    plt.ylabel('Value')\n",
    "    plt.xlabel('No. epoch')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.savefig(plot_path, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_label_pivot(ds):\n",
    "    ds.labels = ds.labels.astype(str)\n",
    "    ds_balance = ds[['labels', 'order']]\n",
    "    ds_balance = ds_balance.pivot_table(index=\"order\", columns=\"labels\", aggfunc=len, fill_value=0)\n",
    "    ds_balance.loc[\"Total\"] = ds_balance.sum()\n",
    "    return ds_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generators(train, val, test, ds_dir, hp):\n",
    "    def orthogonal_rot(image):\n",
    "        return np.rot90(image, np.random.choice([-1, 0, 1]))\n",
    "\n",
    "    if hp['rotation']: preprocessing_function = orthogonal_rot\n",
    "    else: preprocessing_function = None\n",
    "    generator = ImageDataGenerator(\n",
    "        rescale=1./255.,\n",
    "        preprocessing_function=preprocessing_function,\n",
    "        width_shift_range=hp['width_shift'],\n",
    "        height_shift_range=hp['height_shift']\n",
    "        )\n",
    "    test_generator = ImageDataGenerator(rescale=1./255.) \n",
    "\n",
    "    train_gen = generator.flow_from_dataframe(\n",
    "        train,\n",
    "        directory=ds_dir,\n",
    "        x_col='filename',\n",
    "        y_col='labels',\n",
    "        class_mode='categorical',\n",
    "        target_size=hp['model_name_size'][1][:2],\n",
    "        batch_size=hp['batch_size'],\n",
    "        color_mode=hp['color_mode']\n",
    "    )\n",
    "    val_gen = test_generator.flow_from_dataframe(\n",
    "        val,\n",
    "        directory=ds_dir,\n",
    "        x_col='filename',\n",
    "        y_col='labels',\n",
    "        class_mode='categorical',\n",
    "        target_size=hp['model_name_size'][1][:2],\n",
    "        batch_size=hp['batch_size'],\n",
    "        color_mode=hp['color_mode']\n",
    "    )\n",
    "    test_gen = test_generator.flow_from_dataframe(\n",
    "        test,\n",
    "        directory=ds_dir,\n",
    "        x_col='filename',\n",
    "        y_col='labels',\n",
    "        class_mode='categorical',\n",
    "        target_size=hp['model_name_size'][1][:2],\n",
    "        batch_size=hp['batch_size'],\n",
    "        color_mode=hp['color_mode'],\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    return train_gen, val_gen, test_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_resnet(hp):\r\n",
    "    if hp['train_layers']: weights = None\r\n",
    "    else: weights = 'imagenet'\r\n",
    "\r\n",
    "    if hp['model_name_size'][0] == 'resnet50':\r\n",
    "        preprocess_input = tf.keras.applications.resnet.preprocess_input\r\n",
    "        base_model = ResNet50(\r\n",
    "            include_top=False,\r\n",
    "            weights = weights,\r\n",
    "            input_shape=hp['model_name_size'][1],\r\n",
    "            pooling=hp['pooling'],\r\n",
    "            classes=2\r\n",
    "        )\r\n",
    "    if hp['model_name_size'][0] == 'resnet50v2':\r\n",
    "        preprocess_input = tf.keras.applications.resnet_v2.preprocess_input\r\n",
    "        base_model = ResNet50V2(\r\n",
    "            include_top=False,\r\n",
    "            weights=weights, #'imagenet'\r\n",
    "            input_shape=hp['model_name_size'][1],\r\n",
    "            pooling=hp['pooling'],\r\n",
    "            classes=2\r\n",
    "        ) \r\n",
    "    if hp['model_name_size'][0] == 'resnet152':\r\n",
    "        preprocess_input = tf.keras.applications.resnet.preprocess_input\r\n",
    "        base_model = ResNet152(\r\n",
    "            include_top=False,\r\n",
    "            weights = weights,\r\n",
    "            input_shape=hp['model_name_size'][1],\r\n",
    "            pooling=hp['pooling'],\r\n",
    "            classes=2\r\n",
    "        )\r\n",
    "    if hp['model_name_size'][0] == 'resnet152v2':\r\n",
    "        preprocess_input = tf.keras.applications.resnet_v2.preprocess_input\r\n",
    "        base_model = ResNet152V2(\r\n",
    "            include_top=False,\r\n",
    "            weights = weights,\r\n",
    "            input_shape=hp['model_name_size'][1],\r\n",
    "            pooling=hp['pooling'],\r\n",
    "            classes=2\r\n",
    "        )\r\n",
    "    return base_model, preprocess_input\r\n",
    "    \r\n",
    "def make_vgg16(hp):\r\n",
    "    preprocess_input = tf.keras.applications.vgg16.preprocess_input\r\n",
    "    if hp['train_layers']: weights = None\r\n",
    "    else: weights = 'imagenet'\r\n",
    "    base_model = VGG16(    \r\n",
    "        include_top=False,\r\n",
    "        weights = weights,\r\n",
    "        input_shape=hp['model_name_size'][1],\r\n",
    "        pooling=hp['pooling'],\r\n",
    "        classes=2\r\n",
    "    )\r\n",
    "    return base_model, preprocess_input\r\n",
    "\r\n",
    "def make_vgg19(hp):\r\n",
    "    preprocess_input = tf.keras.applications.vgg19.preprocess_input\r\n",
    "    if hp['train_layers']: weights = None\r\n",
    "    else: weights = 'imagenet'\r\n",
    "    base_model = VGG19(    \r\n",
    "        include_top=False,\r\n",
    "        weights = weights,\r\n",
    "        input_shape=hp['model_name_size'][1],\r\n",
    "        pooling=hp['pooling'],\r\n",
    "        classes=2\r\n",
    "    )\r\n",
    "    return base_model, preprocess_input\r\n",
    "\r\n",
    "def make_model(hp):\r\n",
    "    if hp['model_name_size'][0] in ['resnet50', 'resnet50v2', 'resnet152', 'resnet152v2']: base_model, preprocess_input = make_resnet(hp)\r\n",
    "    if hp['model_name_size'][0] == 'vgg16': base_model, preprocess_input = make_vgg16(hp)\r\n",
    "    if hp['model_name_size'][0] == 'vgg19': base_model, preprocess_input = make_vgg19(hp)\r\n",
    "    if not hp['train_layers']: base_model.trainable = False\r\n",
    "\r\n",
    "    x = Flatten()(base_model.output)\r\n",
    "    x = Dense(hp['dense'], activation='relu')(x)\r\n",
    "    \r\n",
    "    predictions = Dense(2, activation=hp[\"activation\"])(x)\r\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\r\n",
    "\r\n",
    "    model.compile(\r\n",
    "        optimizer=optimizers.Adam(learning_rate=hp['lr']),\r\n",
    "        loss='binary_crossentropy',\r\n",
    "        metrics=[\"acc\", talos.utils.metrics.f1score])\r\n",
    "    # https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/\r\n",
    "\r\n",
    "    # plot_model(model, to_file= 'model_plot.pdf', show_shapes=True, show_layer_names=False)\r\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_dataset(DF_PATH, hp, undersample):\n",
    "    ds = pd.read_csv(DF_PATH, usecols=['filename', 'labels', 'order'])\n",
    "    ds = ds.dropna(subset=['labels'])\n",
    "    ds.labels = ds.labels.apply(ast.literal_eval)\n",
    "    print(f\"Original: {ds.shape}\")\n",
    "\n",
    "    if undersample:\n",
    "        rus = RandomUnderSampler(sampling_strategy='all')\n",
    "        ds, _ = rus.fit_resample(ds, ds.labels.astype(str)) \n",
    "    ds = ds.sample(hp[\"samples\"], random_state=8)\n",
    "    # ds_balance = order_label_pivot(ds)\n",
    "    # print(ds_balance)\n",
    "    TRAIN, val_test = train_test_split(ds, test_size=0.5, random_state=8)\n",
    "    VAL, TEST = train_test_split(val_test, test_size=0.5, random_state=8)\n",
    "    print(f\"Train: {TRAIN.shape}\\nVal: {VAL.shape}\\nTest: {TEST.shape}\")\n",
    "    return TRAIN, VAL, TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapper(x, y, x_val, y_val, hp):\n",
    "    DS_DIR = Path('c:/Users/flori/download/subset')\n",
    "    DF_PATH = Path('C:/Users/flori/OneDrive/Documents/Uni/8_Master_thesis/code/subset_logs/20210518-001138.csv')\n",
    "\n",
    "    model = make_model(hp)\n",
    "    # plot_model(model, to_file= 'plots/model_plot_{}.pdf'.format(hp['experiment']), show_shapes=True, show_layer_names=False)\n",
    "    train_df, val_df, test_df = gen_dataset(DF_PATH, hp, undersample=False)\n",
    "    train_gen, val_gen, test_gen = make_generators(train_df, val_df, test_df, DS_DIR, hp)\n",
    "\n",
    "    # es = tf.keras.callbacks.EarlyStopping(monitor='val_f1score', min_delta=0.005, patience=3, verbose=1,mode='max')\n",
    "    out = model.fit(\n",
    "        train_gen,\n",
    "        validation_data=val_gen,\n",
    "        epochs=hp['epochs'],\n",
    "        verbose=1\n",
    "        ,callbacks=[] #es \n",
    "        ,workers=8\n",
    "        ,max_queue_size=16\n",
    "    )\n",
    "    # print(model.summary())\n",
    "\n",
    "    # plot_history(out, hp['experiment'])\n",
    "    return out, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 4000\n",
    "params = {\n",
    "    \"experiment\": ['transfer'],\n",
    "    \"samples\": [samples],\n",
    "    \"color_mode\": [\"rgb\"],\n",
    "    \"epochs\": [7],\n",
    "    \"pooling\": ['avg'], #, 'max'\n",
    "\t\"lr\": [0.001], #[0.0001, 0.001, 0.01]\n",
    "\t\"batch_size\": [32], # [16, 32, 64]\n",
    "    \"rotation\": [True], # [0, 90, 180]\n",
    "    \"width_shift\": [0], #[0, 0.1, 0.2],\n",
    "    \"height_shift\": [0], #[0, 0.1, 0.2],\n",
    "    \"activation\": [\"sigmoid\"], # [\"sigmoid\", \"softmax\"]\n",
    "    \"loss_function\": [\"categorical_crossentropy\"], # was binary  \"categorical_crossentropy\", \"sparse_categorical_crossentropy\"\n",
    "    \"dense\": [1024], # [512, 1024],\n",
    "    \"model_name_size\": [[\"resnet50\", (224,224,3)],\n",
    "                        # [\"resnet50v2\", (224,224,3)],\n",
    "                        # [\"resnet152\", (224,224,3)],\n",
    "                        # [\"resnet152v2\", (224,224,3)],\n",
    "                        # [\"vgg16\", (224,224,3)],\n",
    "                        # [\"vgg19\", (224,224,3)]\n",
    "                        ],\n",
    "    \"train_layers\": [False]\n",
    "}\n",
    "\n",
    "dummy_x, dummy_y = np.empty(1), np.empty(1)\n",
    "\n",
    "# autonomio.github.io/talos/#/\n",
    "scan = talos.Scan(\n",
    "    x=dummy_x,\n",
    "    y=dummy_y,\n",
    "    model=wrapper,\n",
    "    params=params,\n",
    "    experiment_name='talos',\n",
    "    print_params=True,\n",
    "    save_weights=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet_v2 import ResNet50V2, ResNet101V2, ResNet152V2\n",
    "\n",
    "# resnet_model = ResNet50V2(weights='imagenet')\n",
    "# resnet_model.summary()\n",
    "\n",
    "# resnet_model = ResNet101V2(weights='imagenet')\n",
    "# resnet_model.summary()\n",
    "\n",
    "resnet_model = ResNet152V2(weights='imagenet')\n",
    "# resnet_model.summary()\n",
    "\n",
    "resnet_model.count_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_predict = tf.keras.models.load_model('models/model_tuned_200000.h5')\n",
    "DS_DIR = Path('c:/Users/flori/download/subset')\n",
    "DF_PATH = Path('C:/Users/flori/OneDrive/Documents/Uni/8_Master_thesis/code/subset_logs/20210518-001138.csv')\n",
    "\n",
    "hp = {\n",
    "    \"samples\": 2000,\n",
    "\t\"batch_size\": 32,                         # [16, 32, 64]\n",
    "    \"rotation\": True,                         # [True, False]\n",
    "    \"width_shift\": 0,                         # [0, 0.1, 0.2],\n",
    "    \"height_shift\": 0,                        # [0, 0.1, 0.2],\n",
    "    \"input_shape\": (224,224,3),               # [(64,64,1), (128,128,1)]\n",
    "    \"color_mode\": \"rgb\",\n",
    "    \"model_name_size\": [\"resnet50\", (224,224,3)]                # [\"rgb\", \"grayscale\"]\n",
    "}\n",
    "train_df, val_df, test_df = gen_dataset(DF_PATH, hp, undersample=False)\n",
    "train_gen, val_gen, test_gen = make_generators(train_df, val_df, test_df, DS_DIR, hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['resnet50', 'resnet50v2', 'resnet152v2', 'resnet152v2', 'vgg16', 'vgg19']\n",
    "\n",
    "out = pd.DataFrame([], columns=['experiment', 'test_f1score', 'test_accuracy'])\n",
    "for i in range(6):\n",
    "    model_predict = activate_model(scan, i)\n",
    "    preds = model_predict.predict(\n",
    "        test_gen,\n",
    "        # steps=10,\n",
    "        verbose=1,\n",
    "        workers=8,\n",
    "        max_queue_size=16)\n",
    "\n",
    "    y_pred = np.rint(preds).astype(int)\n",
    "    y_true = np.array(test_gen.classes)\n",
    "    y_true = MultiLabelBinarizer().fit_transform(y_true)\n",
    "    f1 = f1_score(y_true[:len(y_pred)], y_pred, average='samples')\n",
    "    acc = accuracy_score(y_true[:len(y_pred)], y_pred)\n",
    "    print(models[i], f1, acc)\n",
    "    \n",
    "    out = out.append({'experiment': models[i], 'test_f1score': f1, \"test_accuracy\": acc}, ignore_index=True)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out.round(3).to_csv('final_out_transfer.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "86a08859f46087af4c4e074af73530229dd7d8037ffe099cb063a6850e6813df"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('python37': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "metadata": {
   "interpreter": {
    "hash": "86a08859f46087af4c4e074af73530229dd7d8037ffe099cb063a6850e6813df"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}